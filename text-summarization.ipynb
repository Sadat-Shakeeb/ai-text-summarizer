{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6004344,"sourceType":"datasetVersion","datasetId":3438844}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-21T08:02:40.409777Z","iopub.execute_input":"2026-01-21T08:02:40.410070Z","iopub.status.idle":"2026-01-21T08:02:40.707571Z","shell.execute_reply.started":"2026-01-21T08:02:40.410023Z","shell.execute_reply":"2026-01-21T08:02:40.706831Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/samsum-dataset-text-summarization/samsum-train.csv\n/kaggle/input/samsum-dataset-text-summarization/samsum-test.csv\n/kaggle/input/samsum-dataset-text-summarization/samsum-validation.csv\n/kaggle/input/samsum-dataset-text-summarization/samsum_dataset/dataset_dict.json\n/kaggle/input/samsum-dataset-text-summarization/samsum_dataset/validation/state.json\n/kaggle/input/samsum-dataset-text-summarization/samsum_dataset/validation/dataset_info.json\n/kaggle/input/samsum-dataset-text-summarization/samsum_dataset/validation/data-00000-of-00001.arrow\n/kaggle/input/samsum-dataset-text-summarization/samsum_dataset/test/state.json\n/kaggle/input/samsum-dataset-text-summarization/samsum_dataset/test/dataset_info.json\n/kaggle/input/samsum-dataset-text-summarization/samsum_dataset/test/data-00000-of-00001.arrow\n/kaggle/input/samsum-dataset-text-summarization/samsum_dataset/train/state.json\n/kaggle/input/samsum-dataset-text-summarization/samsum_dataset/train/dataset_info.json\n/kaggle/input/samsum-dataset-text-summarization/samsum_dataset/train/data-00000-of-00001.arrow\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install -q \\\n  transformers==4.41.2 \\\n  datasets==2.19.1 \\\n  evaluate \\\n  rouge-score \\\n  sentencepiece\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T08:02:40.708448Z","iopub.execute_input":"2026-01-21T08:02:40.708822Z","iopub.status.idle":"2026-01-21T08:02:44.326756Z","shell.execute_reply.started":"2026-01-21T08:02:40.708798Z","shell.execute_reply":"2026-01-21T08:02:44.325818Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# IMPORTS","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport re\nimport numpy as np\nimport torch\n\nfrom datasets import Dataset\nfrom transformers import (\n    T5ForConditionalGeneration,\n    T5TokenizerFast,\n    Seq2SeqTrainer,\n    Seq2SeqTrainingArguments,\n    DataCollatorForSeq2Seq,\n    EarlyStoppingCallback\n)\n\nimport evaluate\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T08:02:48.826390Z","iopub.execute_input":"2026-01-21T08:02:48.826710Z","iopub.status.idle":"2026-01-21T08:02:55.022271Z","shell.execute_reply.started":"2026-01-21T08:02:48.826668Z","shell.execute_reply":"2026-01-21T08:02:55.021681Z"}},"outputs":[{"name":"stderr","text":"2026-01-21 08:02:52.492709: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1768982572.516578     211 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1768982572.524015     211 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1768982572.542981     211 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768982572.543007     211 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768982572.543010     211 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768982572.543012     211 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T08:02:55.023159Z","iopub.execute_input":"2026-01-21T08:02:55.023734Z","iopub.status.idle":"2026-01-21T08:02:55.082356Z","shell.execute_reply.started":"2026-01-21T08:02:55.023691Z","shell.execute_reply":"2026-01-21T08:02:55.081512Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"# LOAD DATASET","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv(\n    \"/kaggle/input/samsum-dataset-text-summarization/samsum-train.csv\"\n)\nval_df = pd.read_csv(\n    \"/kaggle/input/samsum-dataset-text-summarization/samsum-validation.csv\"\n)\n\ntrain_dataset = Dataset.from_pandas(train_df)\nval_dataset = Dataset.from_pandas(val_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T08:03:53.913086Z","iopub.execute_input":"2026-01-21T08:03:53.913428Z","iopub.status.idle":"2026-01-21T08:03:54.286354Z","shell.execute_reply.started":"2026-01-21T08:03:53.913402Z","shell.execute_reply":"2026-01-21T08:03:54.285531Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"train_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T08:04:00.442041Z","iopub.execute_input":"2026-01-21T08:04:00.442619Z","iopub.status.idle":"2026-01-21T08:04:00.467651Z","shell.execute_reply.started":"2026-01-21T08:04:00.442586Z","shell.execute_reply":"2026-01-21T08:04:00.466776Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"             id                                           dialogue  \\\n0      13818513  Amanda: I baked  cookies. Do you want some?\\r\\...   \n1      13728867  Olivia: Who are you voting for in this electio...   \n2      13681000  Tim: Hi, what's up?\\r\\nKim: Bad mood tbh, I wa...   \n3      13730747  Edward: Rachel, I think I'm in ove with Bella....   \n4      13728094  Sam: hey  overheard rick say something\\r\\nSam:...   \n...         ...                                                ...   \n14727  13863028  Romeo: You are on my â€˜People you may knowâ€™ lis...   \n14728  13828570  Theresa: <file_photo>\\r\\nTheresa: <file_photo>...   \n14729  13819050  John: Every day some bad news. Japan will hunt...   \n14730  13828395  Jennifer: Dear Celia! How are you doing?\\r\\nJe...   \n14731  13729017  Georgia: are you ready for hotel hunting? We n...   \n\n                                                 summary  \n0      Amanda baked cookies and will bring Jerry some...  \n1      Olivia and Olivier are voting for liberals in ...  \n2      Kim may try the pomodoro technique recommended...  \n3      Edward thinks he is in love with Bella. Rachel...  \n4      Sam is confused, because he overheard Rick com...  \n...                                                  ...  \n14727  Romeo is trying to get Greta to add him to her...  \n14728  Theresa is at work. She gets free food and fre...  \n14729  Japan is going to hunt whales again. Island an...  \n14730  Celia couldn't make it to the afternoon with t...  \n14731  Georgia and Juliette are looking for a hotel i...  \n\n[14732 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>dialogue</th>\n      <th>summary</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>13818513</td>\n      <td>Amanda: I baked  cookies. Do you want some?\\r\\...</td>\n      <td>Amanda baked cookies and will bring Jerry some...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>13728867</td>\n      <td>Olivia: Who are you voting for in this electio...</td>\n      <td>Olivia and Olivier are voting for liberals in ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>13681000</td>\n      <td>Tim: Hi, what's up?\\r\\nKim: Bad mood tbh, I wa...</td>\n      <td>Kim may try the pomodoro technique recommended...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>13730747</td>\n      <td>Edward: Rachel, I think I'm in ove with Bella....</td>\n      <td>Edward thinks he is in love with Bella. Rachel...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>13728094</td>\n      <td>Sam: hey  overheard rick say something\\r\\nSam:...</td>\n      <td>Sam is confused, because he overheard Rick com...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>14727</th>\n      <td>13863028</td>\n      <td>Romeo: You are on my â€˜People you may knowâ€™ lis...</td>\n      <td>Romeo is trying to get Greta to add him to her...</td>\n    </tr>\n    <tr>\n      <th>14728</th>\n      <td>13828570</td>\n      <td>Theresa: &lt;file_photo&gt;\\r\\nTheresa: &lt;file_photo&gt;...</td>\n      <td>Theresa is at work. She gets free food and fre...</td>\n    </tr>\n    <tr>\n      <th>14729</th>\n      <td>13819050</td>\n      <td>John: Every day some bad news. Japan will hunt...</td>\n      <td>Japan is going to hunt whales again. Island an...</td>\n    </tr>\n    <tr>\n      <th>14730</th>\n      <td>13828395</td>\n      <td>Jennifer: Dear Celia! How are you doing?\\r\\nJe...</td>\n      <td>Celia couldn't make it to the afternoon with t...</td>\n    </tr>\n    <tr>\n      <th>14731</th>\n      <td>13729017</td>\n      <td>Georgia: are you ready for hotel hunting? We n...</td>\n      <td>Georgia and Juliette are looking for a hotel i...</td>\n    </tr>\n  </tbody>\n</table>\n<p>14732 rows Ã— 3 columns</p>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"train_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T08:04:06.402551Z","iopub.execute_input":"2026-01-21T08:04:06.403445Z","iopub.status.idle":"2026-01-21T08:04:06.408281Z","shell.execute_reply.started":"2026-01-21T08:04:06.403408Z","shell.execute_reply":"2026-01-21T08:04:06.407518Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['id', 'dialogue', 'summary'],\n    num_rows: 14732\n})"},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"# LIGHT TEXT CLEANING","metadata":{}},{"cell_type":"code","source":"def clean_text(text):\n    if text is None:\n        return \"\"\n    text = str(text)\n    text = re.sub(r\"\\s+\", \" \", text)\n    return text.strip()\n\n\ntrain_dataset = train_dataset.map(\n    lambda x: {\n        \"dialogue\": clean_text(x[\"dialogue\"]),\n        \"summary\": clean_text(x[\"summary\"])\n    }\n)\n\nval_dataset = val_dataset.map(\n    lambda x: {\n        \"dialogue\": clean_text(x[\"dialogue\"]),\n        \"summary\": clean_text(x[\"summary\"])\n    }\n)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T08:05:05.972751Z","iopub.execute_input":"2026-01-21T08:05:05.973332Z","iopub.status.idle":"2026-01-21T08:05:07.531119Z","shell.execute_reply.started":"2026-01-21T08:05:05.973286Z","shell.execute_reply":"2026-01-21T08:05:07.530210Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/14732 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1b06f1263374885ace1f5a9024c8516"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/818 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2fc04336f7141a998bccbec2e96c07d"}},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"# TOKENIZER","metadata":{}},{"cell_type":"code","source":"tokenizer = T5TokenizerFast.from_pretrained(\"t5-small\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T08:05:30.142333Z","iopub.execute_input":"2026-01-21T08:05:30.143085Z","iopub.status.idle":"2026-01-21T08:05:31.513209Z","shell.execute_reply.started":"2026-01-21T08:05:30.143055Z","shell.execute_reply":"2026-01-21T08:05:31.512357Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58275c744e2f4a58b033b45fbf353aac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ce20fe036af4dfe8f87a416d2961b12"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b236f3cc96d4316b14d130a1ecbdb44"}},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"# TOKENIZATION (T5-CORRECT)","metadata":{}},{"cell_type":"code","source":"MAX_INPUT_LEN = 512\nMAX_TARGET_LEN = 128\n\ndef preprocess_function(batch):\n    inputs = [\"summarize: \" + d for d in batch[\"dialogue\"]]\n\n    model_inputs = tokenizer(\n        inputs,\n        max_length=MAX_INPUT_LEN,\n        truncation=True\n    )\n\n    with tokenizer.as_target_tokenizer():\n        labels = tokenizer(\n            batch[\"summary\"],\n            max_length=MAX_TARGET_LEN,\n            truncation=True\n        )\n\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T08:05:56.552361Z","iopub.execute_input":"2026-01-21T08:05:56.552996Z","iopub.status.idle":"2026-01-21T08:05:56.558213Z","shell.execute_reply.started":"2026-01-21T08:05:56.552964Z","shell.execute_reply":"2026-01-21T08:05:56.557307Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"train_dataset = train_dataset.map(\n    preprocess_function,\n    batched=True,\n    remove_columns=train_dataset.column_names\n)\n\nval_dataset = val_dataset.map(\n    preprocess_function,\n    batched=True,\n    remove_columns=val_dataset.column_names\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T08:06:04.052299Z","iopub.execute_input":"2026-01-21T08:06:04.052663Z","iopub.status.idle":"2026-01-21T08:06:08.623988Z","shell.execute_reply.started":"2026-01-21T08:06:04.052632Z","shell.execute_reply":"2026-01-21T08:06:08.623349Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/14732 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03af794f7111409b95f5bcb9098543f4"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:3946: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/818 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6e4a0d15ea544f59d05b1cf9b43b8d5"}},"metadata":{}}],"execution_count":13},{"cell_type":"markdown","source":"# DATA COLLATOR (DYNAMIC PADDING)","metadata":{}},{"cell_type":"code","source":"data_collator = DataCollatorForSeq2Seq(\n    tokenizer=tokenizer,\n    model=\"t5-small\"\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T08:25:03.832375Z","iopub.execute_input":"2026-01-21T08:25:03.833150Z","iopub.status.idle":"2026-01-21T08:25:03.836750Z","shell.execute_reply.started":"2026-01-21T08:25:03.833117Z","shell.execute_reply":"2026-01-21T08:25:03.835826Z"}},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":"# ROUGE METRIC","metadata":{}},{"cell_type":"code","source":"rouge = evaluate.load(\"rouge\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T08:26:05.272480Z","iopub.execute_input":"2026-01-21T08:26:05.273330Z","iopub.status.idle":"2026-01-21T08:26:05.875912Z","shell.execute_reply.started":"2026-01-21T08:26:05.273286Z","shell.execute_reply":"2026-01-21T08:26:05.875330Z"}},"outputs":[],"execution_count":28},{"cell_type":"markdown","source":"# ROUGE COMPUTATION FUNCTION","metadata":{}},{"cell_type":"code","source":"def compute_metrics(eval_preds):\n    preds, labels = eval_preds\n\n    # Handle tuple output\n    if isinstance(preds, tuple):\n        preds = preds[0]\n\n    # Convert to int64\n    preds = preds.astype(np.int64)\n\n    # ðŸ”´ CLIP predictions to valid tokenizer range\n    preds = np.clip(preds, 0, tokenizer.vocab_size - 1)\n\n    # Replace -100 in labels and clip\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    labels = labels.astype(np.int64)\n    labels = np.clip(labels, 0, tokenizer.vocab_size - 1)\n\n    # Decode safely\n    decoded_preds = tokenizer.batch_decode(\n        preds.tolist(), skip_special_tokens=True\n    )\n    decoded_labels = tokenizer.batch_decode(\n        labels.tolist(), skip_special_tokens=True\n    )\n\n    result = rouge.compute(\n        predictions=decoded_preds,\n        references=decoded_labels\n    )\n\n    return {\n        \"rouge1\": result[\"rouge1\"],\n        \"rouge2\": result[\"rouge2\"],\n        \"rougeL\": result[\"rougeL\"],\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T08:38:00.893494Z","iopub.execute_input":"2026-01-21T08:38:00.894314Z","iopub.status.idle":"2026-01-21T08:38:00.899902Z","shell.execute_reply.started":"2026-01-21T08:38:00.894285Z","shell.execute_reply":"2026-01-21T08:38:00.899137Z"}},"outputs":[],"execution_count":34},{"cell_type":"markdown","source":"# MODEL","metadata":{}},{"cell_type":"code","source":"model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\nmodel.to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T08:26:13.072172Z","iopub.execute_input":"2026-01-21T08:26:13.072475Z","iopub.status.idle":"2026-01-21T08:26:13.665524Z","shell.execute_reply.started":"2026-01-21T08:26:13.072447Z","shell.execute_reply":"2026-01-21T08:26:13.664936Z"}},"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"T5ForConditionalGeneration(\n  (shared): Embedding(32128, 512)\n  (encoder): T5Stack(\n    (embed_tokens): Embedding(32128, 512)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n              (relative_attention_bias): Embedding(32, 8)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-5): 5 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (decoder): T5Stack(\n    (embed_tokens): Embedding(32128, 512)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n              (relative_attention_bias): Embedding(32, 8)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-5): 5 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n)"},"metadata":{}}],"execution_count":30},{"cell_type":"markdown","source":"# TRAINING ARGUMENTS","metadata":{}},{"cell_type":"code","source":"training_args = Seq2SeqTrainingArguments(\n    output_dir=\"./t5_samsum\",\n\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n\n    learning_rate=3e-4,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n\n    num_train_epochs=10,\n    weight_decay=0.01,\n\n    save_total_limit=2,\n\n    fp16=False,   # ðŸ”´ IMPORTANT\n    logging_steps=100,\n    report_to=\"none\",\n\n    predict_with_generate=True,\n    generation_max_length=128,\n    generation_num_beams=5,\n\n    load_best_model_at_end=True,\n    metric_for_best_model=\"rougeL\",\n    greater_is_better=True\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T08:38:30.153640Z","iopub.execute_input":"2026-01-21T08:38:30.154133Z","iopub.status.idle":"2026-01-21T08:38:30.184049Z","shell.execute_reply.started":"2026-01-21T08:38:30.154106Z","shell.execute_reply":"2026-01-21T08:38:30.183189Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}],"execution_count":35},{"cell_type":"markdown","source":"# SEQ2SEQ TRAINER","metadata":{}},{"cell_type":"code","source":"trainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n)\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T08:39:15.342726Z","iopub.execute_input":"2026-01-21T08:39:15.343238Z","iopub.status.idle":"2026-01-21T08:39:15.351928Z","shell.execute_reply.started":"2026-01-21T08:39:15.343210Z","shell.execute_reply":"2026-01-21T08:39:15.351088Z"}},"outputs":[],"execution_count":40},{"cell_type":"markdown","source":"# TRAIN","metadata":{}},{"cell_type":"code","source":"trainer.train()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T08:41:27.282330Z","iopub.execute_input":"2026-01-21T08:41:27.283051Z","iopub.status.idle":"2026-01-21T09:05:34.170056Z","shell.execute_reply.started":"2026-01-21T08:41:27.283022Z","shell.execute_reply":"2026-01-21T09:05:34.169264Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3684' max='9210' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3684/9210 24:05 < 36:10, 2.55 it/s, Epoch 4/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge1</th>\n      <th>Rouge2</th>\n      <th>Rougel</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.530300</td>\n      <td>1.718375</td>\n      <td>0.480444</td>\n      <td>0.236454</td>\n      <td>0.395888</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.678400</td>\n      <td>1.670835</td>\n      <td>0.485890</td>\n      <td>0.248954</td>\n      <td>0.404348</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.578900</td>\n      <td>1.661458</td>\n      <td>0.483604</td>\n      <td>0.247948</td>\n      <td>0.400348</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1.492000</td>\n      <td>1.661610</td>\n      <td>0.486805</td>\n      <td>0.251114</td>\n      <td>0.403453</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n","output_type":"stream"},{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=3684, training_loss=1.5831041118609401, metrics={'train_runtime': 1446.2449, 'train_samples_per_second': 101.864, 'train_steps_per_second': 6.368, 'total_flos': 6026105341476864.0, 'train_loss': 1.5831041118609401, 'epoch': 4.0})"},"metadata":{}}],"execution_count":43},{"cell_type":"markdown","source":"# Save the Model","metadata":{}},{"cell_type":"code","source":"trainer.save_model(\"./saved_t5_samsum\")\ntokenizer.save_pretrained(\"./saved_t5_samsum\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T09:27:26.752954Z","iopub.execute_input":"2026-01-21T09:27:26.753640Z","iopub.status.idle":"2026-01-21T09:27:27.254767Z","shell.execute_reply.started":"2026-01-21T09:27:26.753607Z","shell.execute_reply":"2026-01-21T09:27:27.254036Z"}},"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"('./saved_t5_samsum/tokenizer_config.json',\n './saved_t5_samsum/special_tokens_map.json',\n './saved_t5_samsum/spiece.model',\n './saved_t5_samsum/added_tokens.json',\n './saved_t5_samsum/tokenizer.json')"},"metadata":{}}],"execution_count":44},{"cell_type":"markdown","source":"# Reload for Inference","metadata":{}},{"cell_type":"code","source":"model = T5ForConditionalGeneration.from_pretrained(\"./saved_t5_samsum\")\ntokenizer = T5TokenizerFast.from_pretrained(\"./saved_t5_samsum\")\n\nmodel.to(device)\nmodel.eval()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T09:27:55.592891Z","iopub.execute_input":"2026-01-21T09:27:55.593525Z","iopub.status.idle":"2026-01-21T09:27:55.936457Z","shell.execute_reply.started":"2026-01-21T09:27:55.593494Z","shell.execute_reply":"2026-01-21T09:27:55.935704Z"}},"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"T5ForConditionalGeneration(\n  (shared): Embedding(32128, 512)\n  (encoder): T5Stack(\n    (embed_tokens): Embedding(32128, 512)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n              (relative_attention_bias): Embedding(32, 8)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-5): 5 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (decoder): T5Stack(\n    (embed_tokens): Embedding(32128, 512)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n              (relative_attention_bias): Embedding(32, 8)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-5): 5 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n)"},"metadata":{}}],"execution_count":45},{"cell_type":"markdown","source":"# Inference Function (Summarization)","metadata":{}},{"cell_type":"code","source":"def summarize_dialogue(text):\n    text = re.sub(r\"\\s+\", \" \", text).strip()\n    text = \"summarize: \" + text\n\n    inputs = tokenizer(\n        text,\n        return_tensors=\"pt\",\n        max_length=512,\n        truncation=True\n    ).to(device)\n\n    with torch.no_grad():\n        summary_ids = model.generate(\n            inputs[\"input_ids\"],\n            max_length=128,\n            num_beams=5,\n            early_stopping=True\n        )\n\n    return tokenizer.decode(\n        summary_ids[0],\n        skip_special_tokens=True\n    )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T09:28:22.833299Z","iopub.execute_input":"2026-01-21T09:28:22.833621Z","iopub.status.idle":"2026-01-21T09:28:22.839063Z","shell.execute_reply.started":"2026-01-21T09:28:22.833594Z","shell.execute_reply":"2026-01-21T09:28:22.838243Z"}},"outputs":[],"execution_count":46},{"cell_type":"markdown","source":"# Test the Model","metadata":{}},{"cell_type":"code","source":"sample_dialogue = \"\"\"\nJohn: I might be late to the meeting.\nAlice: Why?\nJohn: Traffic is terrible.\n\"\"\"\n\nprint(summarize_dialogue(sample_dialogue))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T09:28:43.232145Z","iopub.execute_input":"2026-01-21T09:28:43.232886Z","iopub.status.idle":"2026-01-21T09:28:43.395513Z","shell.execute_reply.started":"2026-01-21T09:28:43.232855Z","shell.execute_reply":"2026-01-21T09:28:43.394885Z"}},"outputs":[{"name":"stdout","text":"John might be late to the meeting.\n","output_type":"stream"}],"execution_count":47},{"cell_type":"code","source":"# Test with a dialogue on a different topic\nsample_dialogue = \"\"\"\nJohn: Hey Sarah, have you seen the latest tech gadget reviews? I found this new smartwatch that's supposed to have amazing health tracking features.\nJohn: It tracks heart rate, blood oxygen levels, sleep patterns, and even stress levels! It sounds like something right up your alley. \nSarah: That sounds really interesting! But Iâ€™ve been trying to cut down on tech distractions. Iâ€™ve heard these devices can be really overwhelming sometimes.\nSarah: I do think itâ€™s cool that they can track so many health metrics though. Iâ€™m curious how accurate they really are.\nJohn: Yeah, me too! There are also some new smartphones coming out with even better cameras and longer battery life. The new flagship model from XYZ brand has some insane specs.\nSarah: Ooh, I havenâ€™t kept up with phones recently, but Iâ€™ve heard the camera quality is getting ridiculously good. Itâ€™s almost like a professional camera in your pocket now!\nSarah: Still, I feel like Iâ€™m fine with my current phone for now. I donâ€™t really feel the need to upgrade unless something really groundbreaking comes out.\nJohn: Totally understand that. Itâ€™s the same with me. But I think the battery life improvements are enough to make me consider it. I hate running out of battery when Iâ€™m out and about.\nSarah: Thatâ€™s fair! Iâ€™m always worried about battery life too. Honestly, I think phones should last at least two full days on a single charge by now.\nJohn: I agree! Itâ€™s so annoying when your phone dies in the middle of the day. I wonder if weâ€™ll ever get to a point where we donâ€™t have to charge our phones every day.\nSarah: That would be amazing! I think as tech improves, battery tech might also catch up. Letâ€™s hope the next generation of phones can last longer!\n\"\"\"\n\nsummary = summarize_dialogue(sample_dialogue)\nprint(\"Summary:\", summary)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T09:29:19.533820Z","iopub.execute_input":"2026-01-21T09:29:19.534134Z","iopub.status.idle":"2026-01-21T09:29:20.066416Z","shell.execute_reply.started":"2026-01-21T09:29:19.534107Z","shell.execute_reply":"2026-01-21T09:29:20.065726Z"}},"outputs":[{"name":"stdout","text":"Summary: John found a new smartwatch with health tracking features. It tracks heart rate, blood oxygen levels, sleep patterns, and even stress levels. The new flagship model from XYZ has insane specs. Sarah is worried about battery life.\n","output_type":"stream"}],"execution_count":48},{"cell_type":"code","source":"import os\nprint(os.listdir(\".\"))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T09:37:01.552793Z","iopub.execute_input":"2026-01-21T09:37:01.553147Z","iopub.status.idle":"2026-01-21T09:37:01.557935Z","shell.execute_reply.started":"2026-01-21T09:37:01.553119Z","shell.execute_reply":"2026-01-21T09:37:01.557319Z"}},"outputs":[{"name":"stdout","text":"['saved_t5_samsum', '.virtual_documents', 't5_samsum']\n","output_type":"stream"}],"execution_count":49},{"cell_type":"markdown","source":"# Model Download for building UI","metadata":{}},{"cell_type":"code","source":"import shutil\n\nmodel_dir = \"./saved_t5_samsum\"\noutput_zip_path = \"saved_summary_model.zip\"\n\nshutil.make_archive(\n    base_name=\"saved_summary_model\",\n    format=\"zip\",\n    root_dir=model_dir\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T09:40:42.933024Z","iopub.execute_input":"2026-01-21T09:40:42.933932Z","iopub.status.idle":"2026-01-21T09:40:55.293941Z","shell.execute_reply.started":"2026-01-21T09:40:42.933896Z","shell.execute_reply":"2026-01-21T09:40:55.293229Z"}},"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/saved_summary_model.zip'"},"metadata":{}}],"execution_count":50},{"cell_type":"code","source":"from IPython.display import FileLink\n\n# Display a download link\nFileLink(output_zip_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T09:41:09.623167Z","iopub.execute_input":"2026-01-21T09:41:09.623479Z","iopub.status.idle":"2026-01-21T09:41:09.628682Z","shell.execute_reply.started":"2026-01-21T09:41:09.623451Z","shell.execute_reply":"2026-01-21T09:41:09.628039Z"}},"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/saved_summary_model.zip","text/html":"<a href='saved_summary_model.zip' target='_blank'>saved_summary_model.zip</a><br>"},"metadata":{}}],"execution_count":51},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}